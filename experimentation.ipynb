{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pasting all of my param options into one spot\n",
    "'''\n",
    "parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--text', default=None, help=\"text prompt\")\n",
    "    parser.add_argument('--negative', default='', type=str, help=\"negative text prompt\")\n",
    "    parser.add_argument('-O', action='store_true', help=\"equals --fp16 --cuda_ray --dir_text\")\n",
    "    parser.add_argument('-O2', action='store_true', help=\"equals --fp16 --dir_text\")\n",
    "    parser.add_argument('--test', action='store_true', help=\"test mode\")\n",
    "    parser.add_argument('--save_mesh', action='store_true', help=\"export an obj mesh with texture\")\n",
    "    parser.add_argument('--eval_interval', type=int, default=10, help=\"evaluate on the valid set every interval epochs\")\n",
    "    parser.add_argument('--workspace', type=str, default='workspace')\n",
    "    parser.add_argument('--guidance', type=str, default='stable-diffusion', help='choose from [stable-diffusion, clip]')\n",
    "    parser.add_argument('--seed', type=int, default=0)\n",
    "\n",
    "    ### training options\n",
    "    parser.add_argument('--iters', type=int, default=10000, help=\"training iters\")\n",
    "    parser.add_argument('--lr', type=float, default=1e-3, help=\"initial learning rate\")\n",
    "    parser.add_argument('--ckpt', type=str, default='latest')\n",
    "    parser.add_argument('--cuda_ray', action='store_true', help=\"use CUDA raymarching instead of pytorch\")\n",
    "    parser.add_argument('--max_steps', type=int, default=1024, help=\"max num steps sampled per ray (only valid when using --cuda_ray)\")\n",
    "    parser.add_argument('--num_steps', type=int, default=64, help=\"num steps sampled per ray (only valid when not using --cuda_ray)\")\n",
    "    parser.add_argument('--upsample_steps', type=int, default=64, help=\"num steps up-sampled per ray (only valid when not using --cuda_ray)\")\n",
    "    parser.add_argument('--update_extra_interval', type=int, default=16, help=\"iter interval to update extra status (only valid when using --cuda_ray)\")\n",
    "    parser.add_argument('--max_ray_batch', type=int, default=4096, help=\"batch size of rays at inference to avoid OOM (only valid when not using --cuda_ray)\")\n",
    "    parser.add_argument('--albedo_iters', type=int, default=1000, help=\"training iters that only use albedo shading\")\n",
    "    # model options\n",
    "    parser.add_argument('--bg_radius', type=float, default=1.4, help=\"if positive, use a background model at sphere(bg_radius)\")\n",
    "    parser.add_argument('--density_thresh', type=float, default=10, help=\"threshold for density grid to be occupied\")\n",
    "    # network backbone\n",
    "    parser.add_argument('--fp16', action='store_true', help=\"use amp mixed precision training\")\n",
    "    parser.add_argument('--backbone', type=str, default='grid', help=\"nerf backbone, choose from [grid, vanilla]\")\n",
    "    # rendering resolution in training, decrease this if CUDA OOM.\n",
    "    parser.add_argument('--w', type=int, default=64, help=\"render width for NeRF in training\")\n",
    "    parser.add_argument('--h', type=int, default=64, help=\"render height for NeRF in training\")\n",
    "    parser.add_argument('--jitter_pose', action='store_true', help=\"add jitters to the randomly sampled camera poses\")\n",
    "    \n",
    "    ### dataset options\n",
    "    parser.add_argument('--bound', type=float, default=1, help=\"assume the scene is bounded in box(-bound, bound)\")\n",
    "    parser.add_argument('--dt_gamma', type=float, default=0, help=\"dt_gamma (>=0) for adaptive ray marching. set to 0 to disable, >0 to accelerate rendering (but usually with worse quality)\")\n",
    "    parser.add_argument('--min_near', type=float, default=0.1, help=\"minimum near distance for camera\")\n",
    "    parser.add_argument('--radius_range', type=float, nargs='*', default=[1.0, 1.5], help=\"training camera radius range\")\n",
    "    parser.add_argument('--fovy_range', type=float, nargs='*', default=[40, 70], help=\"training camera fovy range\")\n",
    "    parser.add_argument('--dir_text', action='store_true', help=\"direction-encode the text prompt, by appending front/side/back/overhead view\")\n",
    "    parser.add_argument('--negative_dir_text', action='store_true', help=\"also use negative dir text prompt.\")\n",
    "    parser.add_argument('--angle_overhead', type=float, default=30, help=\"[0, angle_overhead] is the overhead region\")\n",
    "    parser.add_argument('--angle_front', type=float, default=60, help=\"[0, angle_front] is the front region, [180, 180+angle_front] the back region, otherwise the side region.\")\n",
    "\n",
    "    parser.add_argument('--lambda_entropy', type=float, default=1e-4, help=\"loss scale for alpha entropy\")\n",
    "    parser.add_argument('--lambda_opacity', type=float, default=0, help=\"loss scale for alpha value\")\n",
    "    parser.add_argument('--lambda_orient', type=float, default=1e-2, help=\"loss scale for orientation\")\n",
    "    parser.add_argument('--lambda_smooth', type=float, default=0, help=\"loss scale for orientation\")\n",
    "\n",
    "    ### GUI options\n",
    "    parser.add_argument('--gui', action='store_true', help=\"start a GUI\")\n",
    "    parser.add_argument('--W', type=int, default=800, help=\"GUI width\")\n",
    "    parser.add_argument('--H', type=int, default=800, help=\"GUI height\")\n",
    "    parser.add_argument('--radius', type=float, default=3, help=\"default GUI camera radius from center\")\n",
    "    parser.add_argument('--fovy', type=float, default=60, help=\"default GUI camera fovy\")\n",
    "    parser.add_argument('--light_theta', type=float, default=60, help=\"default GUI light direction in [0, 180], corresponding to elevation [90, -90]\")\n",
    "    parser.add_argument('--light_phi', type=float, default=0, help=\"default GUI light direction in [0, 360), azimuth\")\n",
    "    parser.add_argument('--max_spp', type=int, default=1, help=\"GUI rendering max sample per pixel\")\n",
    "\n",
    "    opt = parser.parse_args()\n",
    "'''\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "\n",
    "from nerf.provider import NeRFDataset\n",
    "from nerf.utils import *\n",
    "from optimizer import Shampoo\n",
    "\n",
    "from nerf.gui import NeRFGUI\n",
    "\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "def main(opt):\n",
    "\n",
    "    if opt.O:\n",
    "        opt.fp16 = True\n",
    "        opt.dir_text = True\n",
    "        opt.negative_dir_text = True\n",
    "        opt.cuda_ray = True\n",
    "\n",
    "        # opt.lambda_entropy = 1e-4\n",
    "        # opt.lambda_opacity = 0\n",
    "\n",
    "    elif opt.O2:\n",
    "        opt.fp16 = True\n",
    "        opt.dir_text = True\n",
    "        opt.negative_dir_text = True\n",
    "\n",
    "        # opt.lambda_entropy = 1e-4 # necessary to keep non-empty\n",
    "        # opt.lambda_opacity = 3e-3 # no occupancy grid, so use a stronger opacity loss.\n",
    "\n",
    "    if opt.backbone == 'vanilla':\n",
    "        from nerf.network import NeRFNetwork\n",
    "    elif opt.backbone == 'grid':\n",
    "        from nerf.network_grid import NeRFNetwork\n",
    "    else:\n",
    "        raise NotImplementedError(f'--backbone {opt.backbone} is not implemented!')\n",
    "\n",
    "    print(opt)\n",
    "\n",
    "    seed_everything(opt.seed)\n",
    "\n",
    "    model = NeRFNetwork(opt)\n",
    "\n",
    "    print(model)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    if opt.test:\n",
    "        guidance = None # no need to load guidance model at test\n",
    "\n",
    "        trainer = Trainer('df', opt, model, guidance, device=device, workspace=opt.workspace, fp16=opt.fp16, use_checkpoint=opt.ckpt)\n",
    "\n",
    "        if opt.gui:\n",
    "            gui = NeRFGUI(opt, trainer)\n",
    "            gui.render()\n",
    "        \n",
    "        else:\n",
    "            test_loader = NeRFDataset(opt, device=device, type='test', H=opt.H, W=opt.W, size=100).dataloader()\n",
    "            trainer.test(test_loader)\n",
    "            \n",
    "            if opt.save_mesh:\n",
    "                trainer.save_mesh(resolution=256)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        if opt.guidance == 'stable-diffusion':\n",
    "            from nerf.sd import StableDiffusion\n",
    "            guidance = StableDiffusion(device)\n",
    "        elif opt.guidance == 'clip':\n",
    "            from nerf.clip import CLIP\n",
    "            guidance = CLIP(device)\n",
    "        else:\n",
    "            raise NotImplementedError(f'--guidance {opt.guidance} is not implemented.')\n",
    "\n",
    "        optimizer = lambda model: torch.optim.Adam(model.get_params(opt.lr), betas=(0.9, 0.99), eps=1e-15)\n",
    "        # optimizer = lambda model: Shampoo(model.get_params(opt.lr))\n",
    "\n",
    "        train_loader = NeRFDataset(opt, device=device, type='train', H=opt.h, W=opt.w, size=100).dataloader()\n",
    "\n",
    "        scheduler = lambda optimizer: optim.lr_scheduler.LambdaLR(optimizer, lambda iter: 0.1 ** min(iter / opt.iters, 1))\n",
    "        # scheduler = lambda optimizer: optim.lr_scheduler.OneCycleLR(optimizer, max_lr=opt.lr, total_steps=opt.iters, pct_start=0.1)\n",
    "\n",
    "        trainer = Trainer('df', opt, model, guidance, device=device, workspace=opt.workspace, optimizer=optimizer, ema_decay=None, fp16=opt.fp16, lr_scheduler=scheduler, use_checkpoint=opt.ckpt, eval_interval=opt.eval_interval, scheduler_update_every_step=True)\n",
    "\n",
    "        if opt.gui:\n",
    "            trainer.train_loader = train_loader # attach dataloader to trainer\n",
    "\n",
    "            gui = NeRFGUI(opt, trainer)\n",
    "            gui.render()\n",
    "        \n",
    "        else:\n",
    "            valid_loader = NeRFDataset(opt, device=device, type='val', H=opt.H, W=opt.W, size=5).dataloader()\n",
    "\n",
    "            max_epoch = np.ceil(opt.iters / len(train_loader)).astype(np.int32)\n",
    "            trainer.train(train_loader, valid_loader, max_epoch)\n",
    "\n",
    "            # also test\n",
    "            test_loader = NeRFDataset(opt, device=device, type='test', H=opt.H, W=opt.W, size=100).dataloader()\n",
    "            trainer.test(test_loader)\n",
    "\n",
    "            if opt.save_mesh:\n",
    "                trainer.save_mesh(resolution=256)\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--max_spp'], dest='max_spp', nargs=None, const=None, default=1, type=<class 'int'>, choices=None, help='GUI rendering max sample per pixel', metavar=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting args\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--text', default=None, help=\"text prompt\")\n",
    "parser.add_argument('--negative', default='', type=str, help=\"negative text prompt\")\n",
    "parser.add_argument('-O', action='store_true', help=\"equals --fp16 --cuda_ray --dir_text\")\n",
    "parser.add_argument('-O2', action='store_true', help=\"equals --fp16 --dir_text\")\n",
    "parser.add_argument('--test', action='store_true', help=\"test mode\")\n",
    "parser.add_argument('--save_mesh', action='store_true', help=\"export an obj mesh with texture\")\n",
    "parser.add_argument('--eval_interval', type=int, default=10, help=\"evaluate on the valid set every interval epochs\")\n",
    "parser.add_argument('--workspace', type=str, default='workspace')\n",
    "parser.add_argument('--guidance', type=str, default='stable-diffusion', help='choose from [stable-diffusion, clip]')\n",
    "parser.add_argument('--seed', type=int, default=0)\n",
    "\n",
    "### training options\n",
    "parser.add_argument('--iters', type=int, default=10000, help=\"training iters\")\n",
    "parser.add_argument('--lr', type=float, default=1e-3, help=\"initial learning rate\")\n",
    "parser.add_argument('--ckpt', type=str, default='latest')\n",
    "parser.add_argument('--cuda_ray', action='store_true', help=\"use CUDA raymarching instead of pytorch\")\n",
    "parser.add_argument('--max_steps', type=int, default=1024, help=\"max num steps sampled per ray (only valid when using --cuda_ray)\")\n",
    "parser.add_argument('--num_steps', type=int, default=64, help=\"num steps sampled per ray (only valid when not using --cuda_ray)\")\n",
    "parser.add_argument('--upsample_steps', type=int, default=64, help=\"num steps up-sampled per ray (only valid when not using --cuda_ray)\")\n",
    "parser.add_argument('--update_extra_interval', type=int, default=16, help=\"iter interval to update extra status (only valid when using --cuda_ray)\")\n",
    "parser.add_argument('--max_ray_batch', type=int, default=4096, help=\"batch size of rays at inference to avoid OOM (only valid when not using --cuda_ray)\")\n",
    "parser.add_argument('--albedo_iters', type=int, default=1000, help=\"training iters that only use albedo shading\")\n",
    "# model options\n",
    "parser.add_argument('--bg_radius', type=float, default=1.4, help=\"if positive, use a background model at sphere(bg_radius)\")\n",
    "parser.add_argument('--density_thresh', type=float, default=10, help=\"threshold for density grid to be occupied\")\n",
    "# network backbone\n",
    "parser.add_argument('--fp16', action='store_true', help=\"use amp mixed precision training\")\n",
    "parser.add_argument('--backbone', type=str, default='grid', help=\"nerf backbone, choose from [grid, vanilla]\")\n",
    "# rendering resolution in training, decrease this if CUDA OOM.\n",
    "parser.add_argument('--w', type=int, default=64, help=\"render width for NeRF in training\")\n",
    "parser.add_argument('--h', type=int, default=64, help=\"render height for NeRF in training\")\n",
    "parser.add_argument('--jitter_pose', action='store_true', help=\"add jitters to the randomly sampled camera poses\")\n",
    "\n",
    "### dataset options\n",
    "parser.add_argument('--bound', type=float, default=1, help=\"assume the scene is bounded in box(-bound, bound)\")\n",
    "parser.add_argument('--dt_gamma', type=float, default=0, help=\"dt_gamma (>=0) for adaptive ray marching. set to 0 to disable, >0 to accelerate rendering (but usually with worse quality)\")\n",
    "parser.add_argument('--min_near', type=float, default=0.1, help=\"minimum near distance for camera\")\n",
    "parser.add_argument('--radius_range', type=float, nargs='*', default=[1.0, 1.5], help=\"training camera radius range\")\n",
    "parser.add_argument('--fovy_range', type=float, nargs='*', default=[40, 70], help=\"training camera fovy range\")\n",
    "parser.add_argument('--dir_text', action='store_true', help=\"direction-encode the text prompt, by appending front/side/back/overhead view\")\n",
    "parser.add_argument('--negative_dir_text', action='store_true', help=\"also use negative dir text prompt.\")\n",
    "parser.add_argument('--angle_overhead', type=float, default=30, help=\"[0, angle_overhead] is the overhead region\")\n",
    "parser.add_argument('--angle_front', type=float, default=60, help=\"[0, angle_front] is the front region, [180, 180+angle_front] the back region, otherwise the side region.\")\n",
    "\n",
    "parser.add_argument('--lambda_entropy', type=float, default=1e-4, help=\"loss scale for alpha entropy\")\n",
    "parser.add_argument('--lambda_opacity', type=float, default=0, help=\"loss scale for alpha value\")\n",
    "parser.add_argument('--lambda_orient', type=float, default=1e-2, help=\"loss scale for orientation\")\n",
    "parser.add_argument('--lambda_smooth', type=float, default=0, help=\"loss scale for orientation\")\n",
    "\n",
    "### GUI options\n",
    "parser.add_argument('--gui', action='store_true', help=\"start a GUI\")\n",
    "parser.add_argument('--W', type=int, default=800, help=\"GUI width\")\n",
    "parser.add_argument('--H', type=int, default=800, help=\"GUI height\")\n",
    "parser.add_argument('--radius', type=float, default=3, help=\"default GUI camera radius from center\")\n",
    "parser.add_argument('--fovy', type=float, default=60, help=\"default GUI camera fovy\")\n",
    "parser.add_argument('--light_theta', type=float, default=60, help=\"default GUI light direction in [0, 180], corresponding to elevation [90, -90]\")\n",
    "parser.add_argument('--light_phi', type=float, default=0, help=\"default GUI light direction in [0, 360), azimuth\")\n",
    "parser.add_argument('--max_spp', type=int, default=1, help=\"GUI rendering max sample per pixel\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can add args here\n",
    "# Default params\n",
    "Prompt_text = \"a DSLR photo of a delicious hamburger\" #@param {type: 'string'}\n",
    "Training_iters = \"200\" #@param {type: 'integer'}\n",
    "Learning_rate = \"1e-2\" #@param {type: 'number'}\n",
    "Training_nerf_resolution = \"64\"  #@param {type: 'integer'}\n",
    "# CUDA_ray = True #@param {type: 'boolean'}\n",
    "# View_dependent_prompt = True #@param {type: 'boolean'}\n",
    "# FP16 = True #@param {type: 'boolean'}\n",
    "Seed = 0 #@param {type: 'integer'}\n",
    "Lambda_entropy = \"1e-4\" #@param {type: 'number'}\n",
    "Checkpoint = 'scratch' #@param {type: 'string'}\n",
    "\n",
    "\n",
    "#@markdown ---\n",
    "\n",
    "#@markdown ####**Output Settings:**\n",
    "Workspace = \"hamburger\" #@param{type: 'string'}\n",
    "# Save_mesh = True #@param {type: 'boolean'}\n",
    "\n",
    "# processings\n",
    "Prompt_text = \"'\" + Prompt_text + \"'\"\n",
    "\n",
    "args_list = [\n",
    "    \"--iters\", Training_iters,\n",
    "    \"--text\", Prompt_text,\n",
    "    \"--lr\", Learning_rate,\n",
    "    \"--w\", Training_nerf_resolution,\n",
    "    \"--h\", Training_nerf_resolution,\n",
    "    \"--seed\", Seed,\n",
    "    \"--lambda_entropy\", Lambda_entropy,\n",
    "    \"--ckpt\", Checkpoint,\n",
    "    \"--workspace\", Workspace\n",
    "\n",
    "]\n",
    "opt = parser.parse_args(args = args_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iteration testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(H=800, O=False, O2=False, W=800, albedo_iters=1000, angle_front=60, angle_overhead=30, backbone='grid', bg_radius=1.4, bound=1, ckpt='scratch', cuda_ray=False, density_thresh=10, dir_text=False, dt_gamma=0, eval_interval=10, fovy=60, fovy_range=[40, 70], fp16=False, gui=False, guidance='stable-diffusion', h=64, iters=200, jitter_pose=False, lambda_entropy=0.0001, lambda_opacity=0, lambda_orient=0.01, lambda_smooth=0, light_phi=0, light_theta=60, lr=0.01, max_ray_batch=4096, max_spp=1, max_steps=1024, min_near=0.1, negative='', negative_dir_text=False, num_steps=64, radius=3, radius_range=[1.0, 1.5], save_mesh=False, seed=0, test=False, text=\"'a DSLR photo of a delicious hamburger'\", update_extra_interval=16, upsample_steps=64, w=64, workspace='hamburger')\n",
      "NeRFNetwork(\n",
      "  (encoder): GridEncoder: input_dim=3 num_levels=16 level_dim=2 resolution=16 -> 2048 per_level_scale=1.3819 params=(903480, 2) gridtype=tiled align_corners=False\n",
      "  (sigma_net): MLP(\n",
      "    (net): ModuleList(\n",
      "      (0): Linear(in_features=32, out_features=64, bias=True)\n",
      "      (1): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (2): Linear(in_features=64, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (encoder_bg): FreqEncoder: input_dim=3 degree=6 output_dim=39\n",
      "  (bg_net): MLP(\n",
      "    (net): ModuleList(\n",
      "      (0): Linear(in_features=39, out_features=64, bias=True)\n",
      "      (1): Linear(in_features=64, out_features=3, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "[INFO] try to load hugging face access token from the default place, make sure you have run `huggingface-cli login`.\n",
      "[INFO] loading stable diffusion...\n",
      "[INFO] loaded stable diffusion!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>INFO<span style=\"font-weight: bold\">]</span> Trainer: df | <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2022</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>-01_20-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">08</span> | cuda | fp32 | hamburger\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mINFO\u001b[1m]\u001b[0m Trainer: df | \u001b[1;36m2022\u001b[0m-\u001b[1;36m11\u001b[0m-01_20-\u001b[1;36m38\u001b[0m-\u001b[1;36m08\u001b[0m | cuda | fp32 | hamburger\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>INFO<span style=\"font-weight: bold\">]</span> #parameters: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1816247</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mINFO\u001b[1m]\u001b[0m #parameters: \u001b[1;36m1816247\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>INFO<span style=\"font-weight: bold\">]</span> Training from scratch <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mINFO\u001b[1m]\u001b[0m Training from scratch \u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">==&gt; Start Training hamburger Epoch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">lr</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.100000</span> <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "==> Start Training hamburger Epoch \u001b[1;36m1\u001b[0m, \u001b[33mlr\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.100000\u001b[0m \u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0000 (0.0001), lr=0.031623: : 100% 100/100 [00:31<00:00,  3.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">==&gt; Finished Epoch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "==> Finished Epoch \u001b[1;36m1\u001b[0m.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">==&gt; Start Training hamburger Epoch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #808000; text-decoration-color: #808000\">lr</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.031623</span> <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "==> Start Training hamburger Epoch \u001b[1;36m2\u001b[0m, \u001b[33mlr\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.031623\u001b[0m \u001b[33m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=0.0000 (0.0000), lr=0.010000: : 100% 100/100 [00:31<00:00,  3.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">==&gt; Finished Epoch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "==> Finished Epoch \u001b[1;36m2\u001b[0m.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>INFO<span style=\"font-weight: bold\">]</span> training takes <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0419</span> minutes.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0mINFO\u001b[1m]\u001b[0m training takes \u001b[1;36m1.0419\u001b[0m minutes.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">==&gt; Start Test, save results to hamburger/results\n",
       "</pre>\n"
      ],
      "text/plain": [
       "==> Start Test, save results to hamburger/results\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 100/100 [01:51<00:00,  1.11s/it]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">==&gt; Finished Test.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "==> Finished Test.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 100/100 [01:53<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# First want to test iterations w/an example text\n",
    "# Need to also save loss and print it out\n",
    "\n",
    "# Default is 10,000 but more is recommended\n",
    "# Run default up to 20k and save loss + itermediate results\n",
    "trainer = main(opt)\n",
    "\n",
    "# %run main.py -O --text {Prompt_text} --workspace {Workspace} --iters {Training_iters} --lr {Learning_rate} --w {Training_nerf_resolution} --h {Training_nerf_resolution} --seed {Seed} --lambda_entropy {Lambda_entropy} --ckpt {Checkpoint} --save_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [6.193769120727666e-05, 4.301350716559682e-05],\n",
       " 'valid_loss': [],\n",
       " 'results': [],\n",
       " 'checkpoints': ['df_ep0001.pth', 'df_ep0002.pth'],\n",
       " 'best_result': None}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "eda7e54fe21129b67f77862937907ee926f057597a3e2fa1e18ac955e40912b3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
